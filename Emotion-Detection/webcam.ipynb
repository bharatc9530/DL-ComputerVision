{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#live video\n",
    "\n",
    "classifier = cv2.CascadeClassifier(f'haarcascade_frontalface_default.xml')\n",
    "\n",
    "emotion_model = load_model('bestweight.h5')\n",
    "\n",
    "\n",
    "emotion_dim = (48,48)\n",
    "\n",
    "emotion_bw = False \n",
    "\n",
    "emotion_dict = {0: 'angry', 1: 'happy', 2: 'neutral', 3: 'sad', 4: 'disgust', 5: 'fear', 6: 'surprise'}\n",
    "\n",
    "vid_frames = []\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap_video = False\n",
    "\n",
    "if cap_video == True:\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width  = cap.get(cv2.CAP_PROP_FRAME_WIDTH)   # float\n",
    "    height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)  # float\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter('Tests/FaceDetector.mp4', fourcc,10, (int(width), int(height)))\n",
    "while True: \n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.flip(frame, 1,1)\n",
    "    clone = frame.copy()\n",
    "    bboxes = classifier.detectMultiScale(clone)\n",
    "    for i in bboxes: \n",
    "        x, y, width, height = i[0], i[1], i[2], i[3]\n",
    "        x2, y2 = x+ width, y+height\n",
    "        emotion_roi = clone[y:y2, x:x2]\n",
    "        emotion_roi= cv2.cvtColor(emotion_roi, cv2.COLOR_BGR2GRAY)\n",
    "        emotion_roi = cv2.resize(emotion_roi, emotion_dim, interpolation = cv2.INTER_CUBIC)\n",
    "        emotion_roi = emotion_roi/255\n",
    "        emotion_roi = emotion_roi.reshape(1, emotion_roi.shape[0], emotion_roi.shape[1], 1)\n",
    "        #emotion predictions\n",
    "        emotion_predict = emotion_model.predict(emotion_roi)[0]\n",
    "        emotion_idx = np.argmax(emotion_predict)\n",
    "        emotion_cat = emotion_dict[emotion_idx]\n",
    "        emotion_conf = f'{round(np.max(emotion_predict)*100)}%'\n",
    "        cv2.putText(clone, f'{emotion_cat}: {emotion_conf}', (x, y+15), cv2.FONT_HERSHEY_SIMPLEX, .5, (0,0,225), 2)\n",
    "        cv2.rectangle(clone, (x,y), (x2,y2), (0,0,225), 1)\n",
    "        \n",
    "      \n",
    "        \n",
    "        \n",
    "    cv2.imshow('LIVE', clone)\n",
    "    vid_frames.append(clone)\n",
    "    if cap_video == True:\n",
    "        out.write(clone)\n",
    "    if cv2.waitKey(1) & 0xFF ==ord('q'): \n",
    "        break \n",
    "cap.release()\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "if cap_video == True:\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('face.jpeg',cv2.IMREAD_GRAYSCALE)\n",
    "img = cv2.resize(img, (48,48), interpolation = cv2.INTER_CUBIC)\n",
    "img = img/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape\n",
    "img = img.reshape(1, img.shape[0], img.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4053291 , 0.35004976, 0.2446211 ]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_model = load_model('bestweight.h5')\n",
    "emotion_model.predict(img)\n",
    "grayFrame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for idx, i in enumerate(vid_frames): \n",
    "    cv2.imwrite(f'Tests/VidFrames/{idx}.png', i)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "img_loc = [22,52,74, 103]\n",
    "\n",
    "images = []\n",
    "for i in img_loc:\n",
    "    img = cv2.imread(f'Tests/VidFrames/{i}.png')\n",
    "    images.append(img)\n",
    "    \n",
    "\n",
    "stack_img = np.hstack(images)\n",
    "cv2.imwrite('Images/DemoStack.png', stack_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
